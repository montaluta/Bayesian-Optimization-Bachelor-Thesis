{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperyment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importowanie bibliotek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import sklearn.model_selection as skm\n",
    "from time import time\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dla łatwiejszej modyfikacji parametrów\n",
    "RANDOM_STATE = 16\n",
    "N_JOBS = -1\n",
    "CV_SPLITS = 5\n",
    "SCORING = 'roc_auc'\n",
    "DATASET_IDS = [1, 2, 3]\n",
    "N_ITER = 100\n",
    "TEST_SIZE = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TUTAJ PREPROCESSING - wstępna wersja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes, id = 37\n",
    "from sklearn.datasets import fetch_openml\n",
    "df = fetch_openml(data_id = 37)\n",
    "y = df.target\n",
    "X = df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preg    0\n",
       "plas    0\n",
       "pres    0\n",
       "skin    0\n",
       "insu    0\n",
       "mass    0\n",
       "pedi    0\n",
       "age     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(y = tested_positive) / sum(y = tested_negative): 0.536\n"
     ]
    }
   ],
   "source": [
    "# Jak wygląda zbalansowanie danych:\n",
    "print('sum(y = tested_positive) / sum(y = tested_negative):', round(sum(y == 'tested_positive') / (len(y) - sum(y == 'tested_positive')), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1       True\n",
       "2      False\n",
       "3       True\n",
       "4      False\n",
       "       ...  \n",
       "763     True\n",
       "764     True\n",
       "765     True\n",
       "766    False\n",
       "767     True\n",
       "Name: tested_negative, Length: 768, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: ['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "Categorical features: []\n"
     ]
    }
   ],
   "source": [
    "numerical_features = list(X.dtypes[(X.dtypes != 'object') & (X.dtypes != 'category')].index)\n",
    "categorical_features = list(X.dtypes[(X.dtypes == 'object') | (X.dtypes == 'category')].index)\n",
    "\n",
    "print('Numerical features:', numerical_features)\n",
    "print('Categorical features:', categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  \n",
    "    ('scaler', StandardScaler())  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical', numerical_transformer, numerical_features),\n",
    "    ('categorical', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kroswalidacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = skm.KFold(CV_SPLITS, random_state = RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surrogate models, acquisition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURROGATE_MODELS = ['GP', 'RF', 'ET']  # Gaussian Process, Random Forest, Extra Trees\n",
    "ACQUISITION_FUNCTIONS = ['LCB', 'EI', 'PI']  # Lower Confidence Bound, Expected Improvement, Probability of Improvement\n",
    "\n",
    "# Wszystkie kombinacje\n",
    "SURROGATE_ACQ = []\n",
    "for surrogate in SURROGATE_MODELS:\n",
    "    for acq in ACQUISITION_FUNCTIONS:\n",
    "        SURROGATE_ACQ.append({\n",
    "            'name': f'{surrogate}_{acq}',\n",
    "            'base_estimator': surrogate,\n",
    "            'acq_func': acq\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele i hiperparametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    'XGBoost': {\n",
    "        'estimator': XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            enable_categorical=False,\n",
    "            eval_metric='logloss'\n",
    "        ),\n",
    "        'params': {\n",
    "            'bayes': {\n",
    "                # Podstawowe parametry kontrolujące ogólną wydajność\n",
    "                'model__learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "                'model__max_depth': Integer(3, 9),\n",
    "                'model__n_estimators': Integer(50, 300),\n",
    "                \n",
    "                # Najważniejsze parametry regularyzacji\n",
    "                'model__subsample': Real(0.6, 1.0),  # Zapobiega przetrenowaniu\n",
    "                'model__reg_lambda': Real(0, 10)      # L2 na wagach\n",
    "            },\n",
    "            'random': {\n",
    "                'model__learning_rate': np.logspace(-2, -0.1, 100),\n",
    "                'model__max_depth': np.arange(3, 11),\n",
    "                'model__n_estimators': np.arange(50, 201),\n",
    "            },\n",
    "            'grid': {\n",
    "                'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "                'model__max_depth': [3, 6, 9],\n",
    "                'model__n_estimators': [100, 200],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # z LightGBM jest bardzo dużo warningów, których niezbyt wiem jak się pozbyć, ale też nie wiem, czy są istotne\n",
    "    # 'LightGBM': {\n",
    "    #     'estimator': LGBMClassifier(\n",
    "    #         random_state=RANDOM_STATE,\n",
    "    #         force_col_wise=True\n",
    "    #     ),\n",
    "    #     'params': {\n",
    "    #         'bayes': {\n",
    "    #             # Podstawowe parametry kontrolujące ogólną wydajność\n",
    "    #             'model__learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "    #             'model__num_leaves': Integer(31, 100),  # Zwiększ dolny limit do 31\n",
    "    #             'model__n_estimators': Integer(50, 300),\n",
    "                \n",
    "    #             # Najważniejsze parametry regularyzacji\n",
    "    #             'model__subsample': Real(0.6, 1.0),      # Stochastic Gradient Descent\n",
    "    #             'model__feature_fraction': Real(0.5, 1.0),  # Losowy wybór cech\n",
    "    #             'model__reg_lambda': Real(0, 10)          # L2\n",
    "    #         }\n",
    "    #     }\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etap 1: Testowanie wszystkich kombinacji Surrogate + Acquisition Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_config in MODELS.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model_config['estimator'])\n",
    "    ])\n",
    "    \n",
    "    for sur_acq in SURROGATE_ACQ:\n",
    "        searcher = BayesSearchCV(\n",
    "            estimator=pipeline,\n",
    "            search_spaces=model_config['params']['bayes'],\n",
    "            n_iter=N_ITER,\n",
    "            cv=kfold,\n",
    "            scoring=SCORING,\n",
    "            n_jobs=N_JOBS,\n",
    "            random_state=RANDOM_STATE,\n",
    "            optimizer_kwargs={\n",
    "            'base_estimator': sur_acq['base_estimator'],\n",
    "            'acq_func': sur_acq['acq_func']\n",
    "        }\n",
    "        )\n",
    "        \n",
    "        start_time = time()\n",
    "        searcher.fit(X_train, y_train)\n",
    "        elapsed_time = time() - start_time\n",
    "\n",
    "        best_searcher = searcher.best_estimator_\n",
    "        auc_test = roc_auc_score(y_test, best_searcher.predict_proba(X_test)[:, 1])\n",
    "        \n",
    "        surrogate_results.append({\n",
    "            #'dataset': dataset_id,\n",
    "            'model': model_name,\n",
    "            'method': f\"Bayes_{sur_acq['base_estimator']}_{sur_acq['acq_func']}\",\n",
    "            'best_score': round(searcher.best_score_, 4),\n",
    "            'score_test': round(auc_test, 4),\n",
    "            'time': round(elapsed_time, 4),\n",
    "            'best_params': str(searcher.best_params_)\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>best_score</th>\n",
       "      <th>score_test</th>\n",
       "      <th>time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_GP_LCB</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.8633</td>\n",
       "      <td>89.1980</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.012920...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_GP_EI</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>91.7039</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.022964...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_GP_PI</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>0.8669</td>\n",
       "      <td>104.4750</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.018960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_RF_LCB</td>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.8661</td>\n",
       "      <td>42.1657</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.025069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_RF_EI</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>46.6366</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.017681...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_RF_PI</td>\n",
       "      <td>0.7996</td>\n",
       "      <td>0.8648</td>\n",
       "      <td>45.1479</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.079829...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_ET_LCB</td>\n",
       "      <td>0.8016</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>42.3899</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.013649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_ET_EI</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>0.8668</td>\n",
       "      <td>44.0270</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.070285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_ET_PI</td>\n",
       "      <td>0.8018</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>43.7163</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.024522...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        method  best_score  score_test      time  \\\n",
       "0  XGBoost  Bayes_GP_LCB      0.8017      0.8633   89.1980   \n",
       "1  XGBoost   Bayes_GP_EI      0.8027      0.8671   91.7039   \n",
       "2  XGBoost   Bayes_GP_PI      0.7988      0.8669  104.4750   \n",
       "3  XGBoost  Bayes_RF_LCB      0.8024      0.8661   42.1657   \n",
       "4  XGBoost   Bayes_RF_EI      0.8005      0.8693   46.6366   \n",
       "5  XGBoost   Bayes_RF_PI      0.7996      0.8648   45.1479   \n",
       "6  XGBoost  Bayes_ET_LCB      0.8016      0.8649   42.3899   \n",
       "7  XGBoost   Bayes_ET_EI      0.8033      0.8668   44.0270   \n",
       "8  XGBoost   Bayes_ET_PI      0.8018      0.8684   43.7163   \n",
       "\n",
       "                                         best_params  \n",
       "0  OrderedDict([('model__learning_rate', 0.012920...  \n",
       "1  OrderedDict([('model__learning_rate', 0.022964...  \n",
       "2  OrderedDict([('model__learning_rate', 0.018960...  \n",
       "3  OrderedDict([('model__learning_rate', 0.025069...  \n",
       "4  OrderedDict([('model__learning_rate', 0.017681...  \n",
       "5  OrderedDict([('model__learning_rate', 0.079829...  \n",
       "6  OrderedDict([('model__learning_rate', 0.013649...  \n",
       "7  OrderedDict([('model__learning_rate', 0.070285...  \n",
       "8  OrderedDict([('model__learning_rate', 0.024522...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate_results_df = pd.DataFrame(surrogate_results)\n",
    "surrogate_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najlepsze: ET, PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'GP_LCB', 'base_estimator': 'GP', 'acq_func': 'LCB'},\n",
       " {'name': 'GP_EI', 'base_estimator': 'GP', 'acq_func': 'EI'},\n",
       " {'name': 'GP_PI', 'base_estimator': 'GP', 'acq_func': 'PI'},\n",
       " {'name': 'RF_LCB', 'base_estimator': 'RF', 'acq_func': 'LCB'},\n",
       " {'name': 'RF_EI', 'base_estimator': 'RF', 'acq_func': 'EI'},\n",
       " {'name': 'RF_PI', 'base_estimator': 'RF', 'acq_func': 'PI'},\n",
       " {'name': 'ET_LCB', 'base_estimator': 'ET', 'acq_func': 'LCB'},\n",
       " {'name': 'ET_EI', 'base_estimator': 'ET', 'acq_func': 'EI'},\n",
       " {'name': 'ET_PI', 'base_estimator': 'ET', 'acq_func': 'PI'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SURROGATE_ACQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURROGATE_ACQ_CHOSEN = [{'name': 'ET_PI', 'base_estimator': 'ET', 'acq_func': 'PI'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_config in MODELS.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model_config['estimator'])\n",
    "    ])\n",
    "    \n",
    "    # Definicja metod optymalizacji\n",
    "    searchers = [\n",
    "        ('Bayes_ET_PI', BayesSearchCV(\n",
    "            estimator=pipeline,\n",
    "            search_spaces=model_config['params']['bayes'],\n",
    "            n_iter=N_ITER,\n",
    "            cv=kfold,\n",
    "            scoring=SCORING,\n",
    "            n_jobs=N_JOBS,\n",
    "            random_state=RANDOM_STATE,\n",
    "            optimizer_kwargs={\n",
    "            'base_estimator': SURROGATE_ACQ_CHOSEN[0]['base_estimator'],\n",
    "            'acq_func': SURROGATE_ACQ_CHOSEN[0]['acq_func']\n",
    "            }\n",
    "        )),\n",
    "        ('RandomSearch', RandomizedSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_distributions=model_config['params']['random'],\n",
    "            n_iter=N_ITER,\n",
    "            cv=kfold,\n",
    "            scoring=SCORING,\n",
    "            n_jobs=N_JOBS,\n",
    "            random_state=RANDOM_STATE\n",
    "        )),\n",
    "        ('GridSearch', GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=model_config['params']['grid'],\n",
    "            cv=kfold,\n",
    "            scoring=SCORING,\n",
    "            n_jobs=N_JOBS\n",
    "        ))\n",
    "    ]\n",
    "\n",
    "for searcher_name, searcher in searchers:\n",
    "    start_time = time()\n",
    "    searcher.fit(X_train, y_train)\n",
    "    elapsed_time = time() - start_time\n",
    "\n",
    "    best_searcher = searcher.best_estimator_\n",
    "    auc_test = roc_auc_score(y_test, best_searcher.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    results.append({\n",
    "        #'dataset': dataset_id,\n",
    "        'model': model_name,\n",
    "        'method': searcher_name,\n",
    "        'best_score': round(searcher.best_score_, 4),\n",
    "        'score_test': round(auc_test, 4),\n",
    "        'time': round(elapsed_time, 4),\n",
    "        'best_params': str(searcher.best_params_)\n",
    "    })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>best_score</th>\n",
       "      <th>score_test</th>\n",
       "      <th>time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Bayes_ET_PI</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>47.8538</td>\n",
       "      <td>OrderedDict([('model__learning_rate', 0.047213...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>RandomSearch</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>4.0509</td>\n",
       "      <td>{'model__n_estimators': 174, 'model__max_depth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>GridSearch</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.8606</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>{'model__learning_rate': 0.01, 'model__max_dep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        method  best_score  score_test     time  \\\n",
       "0  XGBoost   Bayes_ET_PI      0.7986      0.8714  47.8538   \n",
       "1  XGBoost  RandomSearch      0.7990      0.8641   4.0509   \n",
       "2  XGBoost    GridSearch      0.7951      0.8606   0.9027   \n",
       "\n",
       "                                         best_params  \n",
       "0  OrderedDict([('model__learning_rate', 0.047213...  \n",
       "1  {'model__n_estimators': 174, 'model__max_depth...  \n",
       "2  {'model__learning_rate': 0.01, 'model__max_dep...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
